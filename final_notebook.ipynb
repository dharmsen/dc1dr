{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgPIWGDBzFU7",
        "colab_type": "text"
      },
      "source": [
        "# Data Challenge - Group 16\n",
        "\n",
        "This is the model and results for Data Challenge 1, made by group 16\n",
        "\n",
        "Niels van der Heijden, Oula Osman Abou, Dalton Harmsen, Jip van Rooij, Phillipp Hauck, Shahrukh Tufail, Shadiah Ricardo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ0PTlwpTmrn",
        "colab_type": "text"
      },
      "source": [
        "### Importing all the libraries we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KFa1jfcTroa",
        "colab_type": "code",
        "outputId": "1a85b554-1bd3-48d8-d7e2-66cee51647f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import itertools\n",
        "import multiprocessing.pool\n",
        "import threading\n",
        "from functools import partial\n",
        "import argparse\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import layers, models\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.backend import relu, sigmoid\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import applications\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "from tensorflow.python.saved_model import utils\n",
        "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
        "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def\n",
        "from tensorflow.contrib.session_bundle import exporter\n",
        "from tensorflow.python.lib.io import file_io"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4tIiaFUzEKY",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu3Mwi8AUlCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "![ -f testDataSmall.npz ] || wget -O testDataSmall.npz \"https://www.win.tue.nl/~cdecampos/testDataSmall.npz\"\n",
        "![ -f trainDataSmall.npz ] || wget -O trainDataSmall.npz \"https://www.win.tue.nl/~cdecampos/trainDataSmall.npz\"\n",
        "!rm -fr jobdir/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPLnrr7AUrDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def read_train_data():\n",
        "    start_time = time.time()\n",
        "    data = np.load(\"trainDataSmall.npz\")\n",
        "    X_train = data[\"X_train\"]\n",
        "    Y_train = data[\"Y_train\"]\n",
        "    rot = rotateimg(X_train)\n",
        "    rotclass = rotateclass(Y_train)\n",
        "    return [rot, rotclass]      \n",
        "\n",
        "\n",
        "def read_test_data():\n",
        "    start_time = time.time()\n",
        "    data = np.load(\"testDataSmall.npz\")\n",
        "    X_test = data[\"X_test\"]\n",
        "    Y_test = data[\"Y_test\"]\n",
        "    return [X_test, Y_test]\n",
        "\n",
        "def rotateimg(data):\n",
        "    \"\"\"\n",
        "    Rotates the images given in shape [?,128,128,3]\n",
        "    return images rotated by 3 times 90 degrees in shape [?*4,128,128,3]\n",
        "    \"\"\"\n",
        "    index=0\n",
        "    result=np.empty((len(data)*4,128,128,3))\n",
        "    for rotation in range(0,4):\n",
        "        for img in data:\n",
        "            result[index]=np.rot90(img,rotation)\n",
        "            index=index+1\n",
        "    return result \n",
        "\n",
        "def rotateclass(data):\n",
        "    \"\"\"\n",
        "    Adds up the classification arrays for all the rotated images. Takes input in shape [?,5]\n",
        "    return classifications in shape [?*4,5]\n",
        "    \"\"\"\n",
        "    index=0\n",
        "    result=np.empty((len(data)*4,5))\n",
        "    for rotation in range(0,4):\n",
        "        for classification in data:\n",
        "            result[index]=classification\n",
        "            index=index+1\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eM0KXX0U0qD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = read_train_data()\n",
        "test_data = read_test_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC0fipxfzU7p",
        "colab_type": "text"
      },
      "source": [
        "## Our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4tIN-WhVMCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(6, 6), \n",
        "                  activation='relu',\n",
        "                  input_shape=(128, 128, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='glorot_uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(5, activation='softmax', kernel_initializer='glorot_uniform'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--uN3Bm8rbvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit (train_data[0], train_data[1], validation_split=0.2,  epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOiCjlRnrdCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(test_data[0], test_data[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdC3pmoazayS",
        "colab_type": "text"
      },
      "source": [
        "## Post-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ouln2xngzfEY",
        "colab_type": "text"
      },
      "source": [
        "### Average confidence over classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s3-4JmpVkDY",
        "colab_type": "text"
      },
      "source": [
        "#### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccEw4nHeVNhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_confidence(model, test):\n",
        "    #initialize index and prediction lists\n",
        "    index1 = []\n",
        "    index2 = []\n",
        "    index3 = []\n",
        "    index4 = []\n",
        "    index5 = []\n",
        "    predictions1 = []\n",
        "    predictions2 = []\n",
        "    predictions3 = []\n",
        "    predictions4 = []\n",
        "    predictions5 = []\n",
        "\n",
        "    #get index of each class\n",
        "    for i in range(len(test[1])):\n",
        "      if np.array_equal(test[1][i], [1., 0., 0., 0., 0.]):\n",
        "        index1.append(i)\n",
        "      elif np.array_equal(test[1][i], [0., 1., 0., 0., 0.]):\n",
        "        index2.append(i)\n",
        "      elif np.array_equal(test[1][i], [0., 0., 1., 0., 0.]):\n",
        "        index3.append(i)\n",
        "      elif np.array_equal(test[1][i], [0., 0., 0., 1., 0.]):\n",
        "        index4.append(i)\n",
        "      elif np.array_equal(test[1][i], [0., 0., 0., 0., 1.]):\n",
        "        index5.append(i)\n",
        "    for classnum in range(5):\n",
        "      #predict outcomes per class and take mean\n",
        "      if classnum == 0:\n",
        "        for index in index1:\n",
        "          predictions1.append(model.predict(np.expand_dims(test[0][index], axis=0)))\n",
        "      elif classnum == 1:\n",
        "        for index in index2:\n",
        "          predictions2.append(model.predict(np.expand_dims(test[0][index], axis=0)))\n",
        "      elif classnum == 2:\n",
        "        for index in index3:\n",
        "          predictions3.append(model.predict(np.expand_dims(test[0][index], axis=0)))\n",
        "      elif classnum == 3:\n",
        "        for index in index4:\n",
        "          predictions4.append(model.predict(np.expand_dims(test[0][index], axis=0)))\n",
        "      elif classnum == 4:\n",
        "        for index in index5:\n",
        "          predictions5.append(model.predict(np.expand_dims(test[0][index], axis=0)))\n",
        "    \n",
        "    \n",
        "    print([list(np.mean(x, axis=0)) for x in zip(*predictions1)])\n",
        "    print([list(np.mean(x, axis=0)) for x in zip(*predictions2)])\n",
        "    print([list(np.mean(x, axis=0)) for x in zip(*predictions3)])\n",
        "    print([list(np.mean(x, axis=0)) for x in zip(*predictions4)])\n",
        "    print([list(np.mean(x, axis=0)) for x in zip(*predictions5)])\n",
        "\n",
        "def average_confidence3(model, test):\n",
        "    #initialize index and prediction lists\n",
        "    index1 = []\n",
        "    index2 = []\n",
        "    index3 = []\n",
        "    predictions1 = []\n",
        "    predictions2 = []\n",
        "    predictions3 = []\n",
        "\n",
        "    #get index of each class\n",
        "    for i in range(len(test[1])):\n",
        "      if np.array_equal(test[1][i], [1., 0., 0., 0., 0.]):\n",
        "        index1.append(i)\n",
        "      elif np.array_equal(test[1][i], [0., 1., 0., 0., 0.]) or np.array_equal(test[1][i], [0., 0., 1., 0., 0.]):\n",
        "        index2.append(i)\n",
        "      elif np.array_equal(test[1][i], [0., 0., 0., 1., 0.] or np.array_equal(test[1][i], [0., 0., 0., 0., 1.])):\n",
        "        index3.append(i)\n",
        "    for classnum in range(3):\n",
        "      #predict outcomes per class and take mean\n",
        "      if classnum == 0:\n",
        "        for index in index1:\n",
        "          predictions1.append(model.predict(np.expand_dims(test[0][index], axis=0)))\n",
        "      elif classnum == 1:\n",
        "        for index in index2:\n",
        "          predictions2.append(model.predict(np.expand_dims(test[0][index], axis=0)))\n",
        "      elif classnum == 2:\n",
        "        for index in index3:\n",
        "          predictions3.append(model.predict(np.expand_dims(test[0][index], axis=0)))\n",
        "    \n",
        "    \n",
        "    list1 = ([list(np.mean(x, axis=0)) for x in zip(*predictions1)])\n",
        "    print([list1[0][0], list1[0][1] + list1[0][2], list1[0][3]+ list1[0][4]])\n",
        "    list2 = ([list(np.mean(x, axis=0)) for x in zip(*predictions2)])\n",
        "    print([list2[0][0], list2[0][1] + list2[0][2], list2[0][3]+ list2[0][4]])\n",
        "    list3 = ([list(np.mean(x, axis=0)) for x in zip(*predictions3)])\n",
        "    print([list3[0][0], list3[0][1] + list3[0][2], list3[0][3]+ list3[0][4]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFkaOyN6Y2Zv",
        "colab_type": "text"
      },
      "source": [
        "#### Computing the average confidence over 3 and 5 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3dfGftQZBwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shows the average confidence per class. The first list means when 0 is the true value, and so on. the final 3 lists are the confidences after post-processing.\n",
        "average_confidence(model, test_data)\n",
        "average_confidence3(model, test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqrH5oMuzlLz",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OhFV_4EWUkK",
        "colab_type": "text"
      },
      "source": [
        "#### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDwsNk-3VPKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates a list of all of the true class values.\n",
        "def label_creator(array):\n",
        "  new_array = array\n",
        "  lst = []\n",
        "  for n in new_array:\n",
        "    for i in range(0,5):\n",
        "      if int(n[i]) == 1:\n",
        "        lst.append(i)\n",
        "     \n",
        "\n",
        "  return lst\n",
        "\n",
        "#creates a function which you can use to plot confusion matrixes\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcr2vOCdXp7M",
        "colab_type": "text"
      },
      "source": [
        "#### Plotting the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc5AWrl4XmdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plots 5x5 confusion matrix\n",
        "classes = [0,1,2,3,4]\n",
        "y_predicted = model.predict_classes(test_data[0])\n",
        "Y_test_lst = label_creator(test_data[1])\n",
        "con_mat = tf.math.confusion_matrix(labels = Y_test_lst, predictions = y_predicted)\n",
        "cm = confusion_matrix(Y_test_lst, y_predicted, classes)\n",
        "\n",
        "plot_confusion_matrix(cm, classes, title = 'frist_prototype_contrast', normalize = True, cmap = 'Reds')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhzZ4bJHYPmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plots 3x3 confusion matrix\n",
        "new_cm = np.array([[cm[0][0], cm[0][1]+cm[0][2], cm[0][3]+cm[0][4]],\n",
        "                   [cm[1][0], cm[1][1]+cm[1][2], cm[1][3]+cm[1][4]],\n",
        "                   [cm[2][0], cm[2][1]+cm[2][2], cm[2][3]+cm[2][4]],\n",
        "                   [cm[3][0], cm[3][1]+cm[3][2], cm[3][3]+cm[3][4]],\n",
        "                   [cm[4][0], cm[4][1]+cm[4][2], cm[4][3]+cm[4][4]]\n",
        "                   ])\n",
        "\n",
        "new_cm2 = np.array([[new_cm[0][0], new_cm[0][1], new_cm[0][2]],\n",
        "                   [new_cm[1][0] + new_cm[2][0], new_cm[1][1]+new_cm[2][1], new_cm[1][2]+new_cm[2][2]],\n",
        "                   [new_cm[3][0] + new_cm[4][0], new_cm[3][1]+new_cm[4][1], new_cm[3][2]+new_cm[4][2]]\n",
        "                   ])\n",
        "\n",
        "plot_confusion_matrix(new_cm2, classes, title = 'frist_prototype_contrast', normalize = True, cmap = 'Reds')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}